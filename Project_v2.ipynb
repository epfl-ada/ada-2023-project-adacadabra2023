{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "directory = os.getcwd()\n",
    "data_path = os.path.join(directory, 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the .tar files in the source directory and extract them in the corresponding subfolder\n",
    "tar_files = [file for file in os.listdir(data_path) if file.endswith('.gz')]\n",
    "\n",
    "for tar_file in tar_files:\n",
    "    tar_file_path = os.path.join(data_path, tar_file)\n",
    "\n",
    "    extraction_folder_name = os.path.basename(tar_file_path).split('.', 1)[0]\n",
    "    folder_path = os.path.join(data_path, extraction_folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    with tarfile.open(tar_file_path, 'r') as tar:\n",
    "        tar.extractall(path=folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_to_csv(path, filename):\n",
    "    '''\n",
    "        This function takes as input the path where the .txt file is located as well as the filename and will create a .tsv file \n",
    "        in the same folder from the data in the .txt file. \n",
    "        \n",
    "        The .txt file is read line by line and a dictionary is created to which the different values for each key are appended as \n",
    "        the file is read. The \"nan\" are replaced by empty space ('') to be better recognized when creating a dataframe.\n",
    "    '''\n",
    "    main_path = os.path.join(path, filename)\n",
    "    if not os.path.exists(main_path + '.tsv'):\n",
    "        with gzip.open(main_path + '.txt.gz', 'rt', encoding=\"utf8\") as file_txt:\n",
    "            with open(main_path + '.tsv', 'w', encoding=\"utf8\") as file_tsv:\n",
    "                first = True\n",
    "                obj = {}\n",
    "                for line in file_txt:\n",
    "                    if line == '\\n':\n",
    "                        if first:\n",
    "                            file_tsv.write(\"\\t\".join(obj.keys()) + \"\\n\")\n",
    "                            first=False\n",
    "                        file_tsv.write(\"\\t\".join(obj.values()) + \"\\n\")\n",
    "                        obj = {}\n",
    "                        continue\n",
    "\n",
    "                    line = re.sub(r'\\bnan\\b', '', line)\n",
    "                    key, value = line.strip().split(\":\", 1)\n",
    "                    obj[key] = value\n",
    "                \n",
    "                if obj: file_tsv.write(\"\\t\".join(obj.values()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definining the path for the files\n",
    "RB_path = os.path.join(data_path, 'RateBeer')\n",
    "BA_path = os.path.join(data_path, 'BeerAdvocate')\n",
    "MB_path = os.path.join(data_path, 'matched_beer_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation of the .txt files\n",
    "text_to_csv(RB_path, 'ratings')\n",
    "text_to_csv(RB_path, 'reviews')\n",
    "\n",
    "text_to_csv(BA_path, 'ratings')\n",
    "text_to_csv(BA_path, 'reviews')\n",
    "\n",
    "text_to_csv(MB_path, 'ratings_ba')\n",
    "text_to_csv(MB_path, 'ratings_with_text_ba')\n",
    "text_to_csv(MB_path, 'ratings_rb')\n",
    "text_to_csv(MB_path, 'ratings_with_text_rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assigning variables\n",
    "RB_beers = pd.read_csv(RB_path + '/beers.csv')\n",
    "RB_breweries = pd.read_csv(RB_path + '/breweries.csv')\n",
    "RB_users = pd.read_csv(RB_path + '/users.csv')\n",
    "RB_ratings = pd.read_csv(RB_path + '/ratings.tsv', sep='\\t')\n",
    "RB_reviews = pd.read_csv(RB_path + '/reviews.tsv', sep='\\t')\n",
    "\n",
    "BA_beers = pd.read_csv(BA_path + '/beers.csv')\n",
    "BA_breweries = pd.read_csv(BA_path + '/breweries.csv')\n",
    "BA_users = pd.read_csv(BA_path + '/users.csv')\n",
    "BA_ratings = pd.read_csv(BA_path + '/ratings.tsv', sep='\\t')\n",
    "BA_reviews = pd.read_csv(BA_path + '/reviews.tsv', sep='\\t')\n",
    "\n",
    "MB_beers = pd.read_csv(MB_path + '/beers.csv', header=1)\n",
    "MB_breweries = pd.read_csv(MB_path + '/breweries.csv', header=1)\n",
    "MB_users = pd.read_csv(MB_path + '/users.csv', header=1)\n",
    "MB_users_approx = pd.read_csv(MB_path + '/users_approx.csv', header=1)\n",
    "MB_ratings = pd.read_csv(MB_path + '/ratings.csv', header=1)\n",
    "MB_ratingsBA = pd.read_csv(MB_path + '/ratings_ba.tsv', sep='\\t')\n",
    "MB_ratingsBA_txt = pd.read_csv(MB_path + '/ratings_with_text_ba.tsv', sep='\\t')\n",
    "MB_ratingsRB = pd.read_csv(MB_path + '/ratings_rb.tsv', sep='\\t')\n",
    "MB_ratingsRB_txt = pd.read_csv(MB_path + '/ratings_with_text_rb.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers.nbr_matched_valid_ratings.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(beers)\n",
    "display(breweries)\n",
    "display(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['nbr_ratings'].sort_values(ascending=False).plot(kind='hist', range = (20,1000), bins= 100)\n",
    "# average rating/ overall rating in time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
